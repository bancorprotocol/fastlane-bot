{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastlane_bot.tests.deterministic.base_imports import *\n",
    "from fastlane_bot.data.abi import CARBON_CONTROLLER_ABI, UNISWAP_V3_POOL_ABI, UNISWAP_V2_POOL_ABI, PANCAKESWAP_V3_POOL_ABI, PANCAKESWAP_V2_POOL_ABI\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the test_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matrix = pd.read_csv(r\"fastlane_bot\\tests\\deterministic\\test_matrix.csv\")\n",
    "test_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test_run_name in test_matrix['Test Batch'].unique()[:1]:\n",
    "test_run_name = \"BASE_MULTI_SINGLE_EXTERNAL\"\n",
    "blockchain = test_matrix[test_matrix['Test Batch']==test_run_name]['Blockchain'].values[0]\n",
    "click_options = test_matrix[test_matrix['Test Batch']==test_run_name]['click_options_input'].values[0]\n",
    "new_fork = bool(test_matrix[test_matrix['Test Batch']==test_run_name]['new_fork'].values[0])\n",
    "static_pool_data_filename= [x for x in click_options.split(\" --\") if \"static_pool_data\" in x][0].replace(\"static_pool_data_filename=\",\"\")\n",
    "print(test_run_name, blockchain, static_pool_data_filename, new_fork)\n",
    "print(click_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select a new fork or existing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to add a click option for this\n",
    "if new_fork:\n",
    "    url = create_new_testnet(blockchain=blockchain)\n",
    "    # rewrite the click_options with the new rpc_url generated\n",
    "    click_options = ' --'.join([x for x in click_options.split(\" --\") if \"rpc_url\" not in x] + [f\"rpc_url={url}\"])\n",
    "else:\n",
    "    url= [x for x in click_options.split(\" --\") if \"rpc_url\" in x][0].replace(\"rpc_url=\",\"\")\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the RPC:\n",
    "w3 = Web3(Web3.HTTPProvider(url))\n",
    "assert w3.is_connected() == True, \"Web3 not connected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Carbon Controller contract\n",
    "CarbonController_address = pd.read_csv(r\"fastlane_bot\\data\\multichain_addresses.csv\").query(\"exchange_name=='carbon_v1'\").query(f\"chain=='{blockchain}'\").factory_address.values[0]\n",
    "fromBlock = int(pd.read_csv(r\"fastlane_bot\\data\\multichain_addresses.csv\").query(\"exchange_name=='carbon_v1'\").query(f\"chain=='{blockchain}'\").start_block.values[0])\n",
    "CarbonController = w3.eth.contract(address=CarbonController_address, abi=CARBON_CONTROLLER_ABI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Carbon Strategies and Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current state\n",
    "strategy_created_df, strategy_deleted_df, remaining_carbon_strategies = get_state_of_carbon_strategies(w3, CarbonController, fromBlock=fromBlock)\n",
    "\n",
    "# takes about 4 minutes per 100 strategies\n",
    "# so 450 ~ 18 minutes\n",
    "undeleted_strategies = delete_all_carbon_strategies(w3, CarbonController, blockchain, carbon_strategy_id_owner_list=remaining_carbon_strategies)\n",
    "\n",
    "# These strategies cannot be deleted on Ethereum\n",
    "known_unable_to_delete = {\n",
    "    68737038118029569619601670701217178714718: (\"pDFS\", \"ETH\"), #pDFS \n",
    "    }\n",
    "assert all([x in known_unable_to_delete for x in undeleted_strategies]), f\"Strategies not deleted that are unknown: {undeleted_strategies}\"\n",
    "\n",
    "# Redundant for checking state\n",
    "strategy_created_df, strategy_deleted_df, remaining_carbon_strategies = get_state_of_carbon_strategies(w3, CarbonController, fromBlock=fromBlock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The above resets the testnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the Test State on external pools\n",
    "Since this method uses backdate_pool=True to fetch the current state of the external pools, then ALL the external pools included in a single test bot run must have their states updated prior to initializing the bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pool data\n",
    "static_pool_data_testing_path = os.path.normpath(rf\"fastlane_bot\\data\\blockchain_data\\{blockchain}\\{static_pool_data_filename}.csv\")\n",
    "test_pools = pd.read_csv(static_pool_data_testing_path, dtype=str)\n",
    "\n",
    "# Overwrite the last_updated_block field with a recent block due to bot events fetching bug\n",
    "testing_start_block = int(w3.eth.block_number)\n",
    "test_pools['last_updated_block'] = testing_start_block\n",
    "test_pools.to_csv(static_pool_data_testing_path)\n",
    "\n",
    "# Handle each exchange_type differently for the required updates\n",
    "for index in test_pools.index:\n",
    "    exchange_type = test_pools[\"exchange_type\"][index]\n",
    "    print(test_pools[\"exchange_type\"][index], test_pools[\"exchange\"][index])\n",
    "    handle_exchange_parameters(w3, test_pools.iloc[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional validation to ensure that all states are set correctly\n",
    "# Calls all relevant functions and verifies slot content againt input data\n",
    "run_slot_update_tests(w3, test_pools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start a bot instance to run all tests against\n",
    "- Limitations are one bot per mode per test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the bot\n",
    "child_process = initialize_bot_new(click_options)\n",
    "\n",
    "# Wait until the pool data populates\n",
    "most_recent_log_folder = await_first_iteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impore test strategies\n",
    "test_strategies_path = os.path.normpath(rf\"fastlane_bot\\data\\blockchain_data\\{blockchain}\\test_strategies_{test_run_name}.json\")\n",
    "with open(test_strategies_path) as file:\n",
    "    test_strategies = json.load(file)['test_strategies']\n",
    "    print(f\"{len(test_strategies.keys())} test strategies imported\")\n",
    "\n",
    "# Mark the block that new strats were created\n",
    "strats_created_fromBlock = w3.eth.get_block_number()\n",
    "print(\"strats_created_fromBlock\", strats_created_fromBlock)\n",
    "\n",
    "# populate a dictionary with all the relevant test strategies\n",
    "test_strategy_txhashs = {}\n",
    "for i in range(1,len(test_strategies.keys())+1):\n",
    "    i = str(i)\n",
    "    test_strategy = test_strategies[i]\n",
    "    get_token_approval(w3, test_strategy['token0'], CarbonController.address, test_strategy['wallet'])\n",
    "    get_token_approval(w3, test_strategy['token1'], CarbonController.address, test_strategy['wallet'])\n",
    "    txhash = createStrategy_fromTestDict(w3, CarbonController, test_strategy)\n",
    "    test_strategy_txhashs[i] = {}\n",
    "    test_strategy_txhashs[i]['txhash'] = txhash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect the new state of relevant strategies created\n",
    "strategy_created_df, strategy_deleted_df, remaining_carbon_strategies = get_state_of_carbon_strategies(w3, CarbonController, fromBlock=strats_created_fromBlock)\n",
    "new_strats_created = strategy_created_df[\"id\"].to_list()\n",
    "print(f\"There have been {len(new_strats_created)} new strategies created\")\n",
    "\n",
    "# add the strategy ids\n",
    "for i in test_strategy_txhashs.keys():\n",
    "    test_strategy_txhashs[i]['strategyid'] = strategy_created_df.query(f\"transactionHash == '{test_strategy_txhashs[i]['txhash']}'\").id.values[0]\n",
    "\n",
    "# Wait for the arbs to execute\n",
    "#this could be replaced with a loop searching for a successful tx\n",
    "print(\"Sleeping while arbs are executed...\")\n",
    "if blockchain == 'ethereum':\n",
    "    time.sleep(int(35*len(test_strategy_txhashs.keys()) + 15)) \n",
    "if blockchain == 'coinbase_base':\n",
    "    time.sleep(int(5*len(test_strategy_txhashs.keys()) + 15))     \n",
    "\n",
    "# First layer verification\n",
    "# Check that all strategies recently created have been traded on\n",
    "updated_events_df = get_GenericEvents(w3, CarbonController, \"StrategyUpdated\", fromBlock=strats_created_fromBlock)\n",
    "if len(updated_events_df) == 0:\n",
    "    print(\"Not all strategies created have been traded against\")\n",
    "else:\n",
    "    strategies_traded_against =  list(set(updated_events_df[updated_events_df.reason==1].id.to_list()))\n",
    "if not all(item in strategies_traded_against for item in new_strats_created):\n",
    "    print(\"Not all strategies created have been traded against\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all successful_txs\n",
    "all_successful_txs = glob.glob(os.path.join(most_recent_log_folder, \"*.txt\"))\n",
    "\n",
    "# Read the succussful_txs in as strings\n",
    "txt_all_successful_txs = []\n",
    "for successful_tx in all_successful_txs:\n",
    "    with open(successful_tx, 'r') as file:\n",
    "        j = file.read()\n",
    "        txt_all_successful_txs += [(j)]\n",
    "        file.close()\n",
    "\n",
    "# Successful transactions on Tenderly are marked by status=1\n",
    "actually_txt_all_successful_txs = [tx for tx in txt_all_successful_txs if \"'status': 1\" in tx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import expected test results\n",
    "test_results_path = os.path.normpath(rf\"fastlane_bot\\data\\blockchain_data\\{blockchain}\\test_results_{test_run_name}.json\")\n",
    "with open(test_results_path) as f:\n",
    "    test_datas = json.load(f)['test_data']\n",
    "    f.close()\n",
    "    print(f\"{len(test_datas.keys())} test results imported\")\n",
    "\n",
    "# Loop over the created test strategies and verify test data\n",
    "tests_passed=True\n",
    "for i in test_strategy_txhashs.keys():\n",
    "    search_id = test_strategy_txhashs[i]['strategyid']\n",
    "    print(f\"Evaluating test {i}, {search_id}\")\n",
    "    tx_data = get_tx_data(search_id, actually_txt_all_successful_txs)\n",
    "    clean_tx_data(tx_data)\n",
    "    test_data = test_datas[i]\n",
    "    if tx_data == test_data:\n",
    "        print(f\"Test {i} PASSED\")\n",
    "    else:\n",
    "        print(f\"Test {i} FAILED\")\n",
    "        tests_passed = False\n",
    "if tests_passed:\n",
    "    print(\"ALL TESTS PASSED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terminate the bot background process\n",
    "if child_process.terminate():\n",
    "    print(\"Arb Bot shutdown complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_jsons(json1, json2, ignore_keys=[]):\n",
    "    # Function to compare two values and check if they are within 1%\n",
    "    def is_within_1_percent(val1, val2):\n",
    "        return abs(val1 - val2) / max(abs(val1), abs(val2)) <= 0.01\n",
    "\n",
    "    # Recursive function to iterate through the JSON\n",
    "    def compare(obj1, obj2):\n",
    "        # Ensure both objects are of the same type\n",
    "        if type(obj1) != type(obj2):\n",
    "            return False\n",
    "\n",
    "        if isinstance(obj1, dict):\n",
    "            # Ensure both dicts have the same keys\n",
    "            if set(obj1.keys()) != set(obj2.keys()):\n",
    "                return False\n",
    "            # Recursively compare values of each key\n",
    "            for key in obj1:\n",
    "                if key in ignore_keys:\n",
    "                    continue  # Skip comparison for this key\n",
    "                if not compare(obj1[key], obj2[key]):\n",
    "                    return False\n",
    "        elif isinstance(obj1, list):\n",
    "            # Ensure both lists are of the same length\n",
    "            if len(obj1) != len(obj2):\n",
    "                return False\n",
    "            # Recursively compare each item\n",
    "            for item1, item2 in zip(obj1, obj2):\n",
    "                if not compare(item1, item2):\n",
    "                    return False\n",
    "        elif isinstance(obj1, float) or isinstance(obj1, int):\n",
    "            # Compare numerical values\n",
    "            if not is_within_1_percent(obj1, obj2):\n",
    "                return False\n",
    "        else:\n",
    "            # For non-numeric types, ensure equality\n",
    "            if obj1 != obj2:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    return compare(json1, json2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over the created test strategies and verify test data\n",
    "tests_passed=True\n",
    "for i in test_strategy_txhashs.keys():\n",
    "    search_id = test_strategy_txhashs[i]['strategyid']\n",
    "    print(f\"Evaluating test {i}, {search_id}\")\n",
    "    tx_data = get_tx_data(search_id, actually_txt_all_successful_txs)\n",
    "    clean_tx_data(tx_data)\n",
    "    test_data = test_datas[i]\n",
    "    if compare_jsons(tx_data, test_data, ['trade_index']):\n",
    "        print(f\"Test {i} PASSED\")\n",
    "    else:\n",
    "        print(f\"Test {i} FAILED\")\n",
    "        tests_passed = False\n",
    "if tests_passed:\n",
    "    print(\"ALL TESTS PASSED\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "async_arbbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
